{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb14c46d",
   "metadata": {},
   "source": [
    "# Comparison of Real and Complex Neural Networks Using Cross-Validation and Paired T-Test\n",
    " Description:\n",
    "This section details the comparison of real and complex-valued artificial neural networks, specifically focusing on protein classification. The comparison is based on the mean and standard deviations of metric results obtained from 10-fold cross-validation. A paired t-test is utilized to statistically compare the accuracy results of both methods at each fold. This comparison is conducted separately for DNA, codon, and amino acid sequences.\n",
    "\n",
    "Cross Validation (10 Fold) and T-Test Analysis Steps:\n",
    "\n",
    " 1. DNA Sequence Classification: Complex-ANN vs. Real-ANN\n",
    "\n",
    "- a) Complex-ANN: Cross-validation and metric averages of classification with complex-valued artificial neural networks.\n",
    "- b) Real-ANN: Cross-validation and metric averages of classification with real-valued artificial neural networks.\n",
    "- c) Paired t-test Analysis.\n",
    "\n",
    "\n",
    " 2. Codon Sequence Classification: Complex-ANN vs. Real-ANN\n",
    "\n",
    "- a) Complex-ANN: Cross-validation and metric averages of classification with complex-valued artificial neural networks.\n",
    "- b) Real-ANN: Cross-validation and metric averages of classification with real-valued artificial neural networks.\n",
    "- c) Paired t-test Analysis.\n",
    "\n",
    "3. Amino Acid Sequence Classification: Complex-ANN vs. Real-ANN\n",
    "\n",
    "- a) Complex-ANN: Cross-validation and metric averages of classification with complex-valued artificial neural networks.\n",
    "- b) Real-ANN: Cross-validation and metric averages of classification with real-valued artificial neural networks.\n",
    "- c) Paired t-test Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07a611",
   "metadata": {},
   "source": [
    "# 1. DNA Sequence Classification: Complex-ANN vs. Real-ANN \n",
    "\n",
    "- a) Cross-Validation and Metric Averages of Classification with Complex Value Artificial Neural Networks (10 Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1c79e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Fold 1 Confusion Matrix:\n",
      "[[8 2]\n",
      " [3 7]]\n",
      "Accuracy: 0.7500, Precision: 0.7525, Recall: 0.7500, F1 Score: 0.7494\n",
      "\n",
      "Fold 2 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 3  7]]\n",
      "Accuracy: 0.8500, Precision: 0.8846, Recall: 0.8500, F1 Score: 0.8465\n",
      "\n",
      "Fold 3 Confusion Matrix:\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9000, F1 Score: 0.9000\n",
      "\n",
      "Fold 4 Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "Accuracy: 0.8500, Precision: 0.8535, Recall: 0.8500, F1 Score: 0.8496\n",
      "\n",
      "Fold 5 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 2  8]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 6 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 7 Confusion Matrix:\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9000, F1 Score: 0.9000\n",
      "\n",
      "Fold 8 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 2  8]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 9 Confusion Matrix:\n",
      "[[8 2]\n",
      " [1 9]]\n",
      "Accuracy: 0.8500, Precision: 0.8535, Recall: 0.8500, F1 Score: 0.8496\n",
      "\n",
      "Fold 10 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Average Accuracy: 0.8800 ± 0.0557\n",
      "Average Precision: 0.8887 ± 0.0561\n",
      "Average Recall: 0.8800 ± 0.0557\n",
      "Average F1 Score: 0.8793 ± 0.0560\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "class ComplexDense(Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super(ComplexDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units, 2),\n",
    "                                      initializer='random_normal',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(shape=(self.units, 2),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs_real, inputs_imag = tf.math.real(inputs), tf.math.imag(inputs)\n",
    "        kernel_real, kernel_imag = self.kernel[..., 0], self.kernel[..., 1]\n",
    "        bias_real, bias_imag = self.bias[..., 0], self.bias[..., 1]\n",
    "\n",
    "        output_real = tf.matmul(inputs_real, kernel_real) - tf.matmul(inputs_imag, kernel_imag) + bias_real\n",
    "        output_imag = tf.matmul(inputs_real, kernel_imag) + tf.matmul(inputs_imag, kernel_real) + bias_imag\n",
    "\n",
    "        output = tf.complex(output_real, output_imag)\n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "def complex_tanh(z):\n",
    "    return tf.complex(tf.math.tanh(tf.math.real(z)), tf.math.tanh(tf.math.imag(z)))\n",
    "\n",
    "def wirtinger_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.complex64)\n",
    "    y_pred = tf.cast(y_pred, tf.complex64)\n",
    "    dF_dz = tf.math.conj(y_pred - y_true) \n",
    "    dF_dz_star = (y_pred - y_true)\n",
    "    return tf.math.abs(dF_dz)**2 + tf.math.abs(dF_dz_star)**2\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel(\"D://datasetTEZ//KİNASE_GPCR_DNA_Complex_Encoded.xlsx\")\n",
    "X = np.array([np.array(list(map(float, x_real.strip(\"[]\").split(',')))) + 1j * np.array(list(map(float, x_imag.strip(\"[]\").split(',')))) for x_real, x_imag in zip(data['Real'], data['Imag'])])\n",
    "y = data['label'].values\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies, precisions, recalls, f1_scores, conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Start cross-validation\n",
    "for train_index, test_index in kf.split(X, np.argmax(y, axis=1)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Model definition\n",
    "    input_layer = Input(shape=(X_train.shape[1],), dtype=tf.complex64)\n",
    "    complex_dense1 = ComplexDense(12, activation=complex_tanh)(input_layer)\n",
    "    complex_dense2 = ComplexDense(8, activation=complex_tanh)(complex_dense1)\n",
    "    complex_dense3 = ComplexDense(6, activation=complex_tanh)(complex_dense2)\n",
    "    output_layer = ComplexDense(2, activation=complex_tanh)(complex_dense3)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.005), loss=wirtinger_loss, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, batch_size=10, epochs=80, verbose=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision = precision_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "\n",
    "    # Store the results\n",
    "    conf_matrices.append(cm)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Display the results from all folds\n",
    "for i, cm in enumerate(conf_matrices, 1):\n",
    "    print(f\"Fold {i} Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {accuracies[i-1]:.4f}, Precision: {precisions[i-1]:.4f}, Recall: {recalls[i-1]:.4f}, F1 Score: {f1_scores[i-1]:.4f}\\n\")\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the metrics\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "std_precision = np.std(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "std_recall = np.std(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(f\"Average Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb56e3",
   "metadata": {},
   "source": [
    "- b) Cross-Validation and Metric Averages of Classification with Real-Value Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eba5b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Fold 1 Confusion Matrix:\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 2 Confusion Matrix:\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 3 Confusion Matrix:\n",
      "[[ 7  3]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.8500, Precision: 0.8846, Recall: 0.8500, F1 Score: 0.8465\n",
      "\n",
      "Fold 4 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 0 10]]\n",
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "\n",
      "Fold 5 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 0 10]]\n",
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "\n",
      "Fold 6 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 5  5]]\n",
      "Accuracy: 0.7500, Precision: 0.8333, Recall: 0.7500, F1 Score: 0.7333\n",
      "\n",
      "Fold 7 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 8 Confusion Matrix:\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9000, F1 Score: 0.9000\n",
      "\n",
      "Fold 9 Confusion Matrix:\n",
      "[[ 7  3]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.8500, Precision: 0.8846, Recall: 0.8500, F1 Score: 0.8465\n",
      "\n",
      "Fold 10 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 0 10]]\n",
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "\n",
      "Average Accuracy: 0.9100 ± 0.0768\n",
      "Average Precision: 0.9290 ± 0.0548\n",
      "Average Recall: 0.9100 ± 0.0768\n",
      "Average F1 Score: 0.9074 ± 0.0809\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"D:\\\\datasetTEZ\\\\KİNASE_GPCR_DNA_ReelEncoded.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "data['Encoded'] = data['Encoded'].apply(ast.literal_eval)\n",
    "\n",
    "# Separate attributes and tags\n",
    "X = np.array(data['Encoded'].tolist())\n",
    "y = data['label'].values\n",
    "y = to_categorical(y, num_classes=2)  # Convert labels to one-hot encoded format if needed\n",
    "\n",
    "# Standardize data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies, precisions, recalls, f1_scores, conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Start cross-validation\n",
    "for train_index, test_index in kf.split(X, np.argmax(y, axis=1)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=12, activation='tanh', input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=8, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=6, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, batch_size=10, epochs=80, verbose=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision = precision_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "\n",
    "    # Store the results\n",
    "    conf_matrices.append(cm)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Display the results from all folds\n",
    "for i, cm in enumerate(conf_matrices, 1):\n",
    "    print(f\"Fold {i} Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {accuracies[i-1]:.4f}, Precision: {precisions[i-1]:.4f}, Recall: {recalls[i-1]:.4f}, F1 Score: {f1_scores[i-1]:.4f}\\n\")\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the metrics\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "std_precision = np.std(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "std_recall = np.std(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(f\"Average Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f900b4",
   "metadata": {},
   "source": [
    "- c) Paired t-test: In cross-validation, the accuracy results obtained by both methods in each fold can be directly compared using the paired t-test.\n",
    "\n",
    "\n",
    "According to the test results, t-statistic (-0.9186) and p-value (0.3823) results show that there is no statistically significant difference in accuracy performance between the two deep learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9c7a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -0.9185586535436918, P-value: 0.3822841681565753\n",
      "There is no statistically significant difference between the two models.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Accuracy results of Real and Complex method:\n",
    "complex_method1 = [0.7500, 0.8500, 0.9000, 0.8500, 0.9000, 0.9500, 0.9000, 0.9000, 0.8500, 0.9500]\n",
    "real_method2 = [0.9000, 0.9000, 0.8500, 1.0000, 1.0000, 0.7500, 0.9500, 0.9000, 0.8500, 1.0000]\n",
    "\n",
    "# Paired t-test\n",
    "t_stat, p_value = ttest_rel(complex_method1, real_method2)\n",
    "\n",
    "print(f\"T-Statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the two models.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the two models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec794d",
   "metadata": {},
   "source": [
    "# 2.\tCodon Sequence Classification: Complex-ANN vs. Real-ANN\n",
    "- a) Complex-ANN: Cross-validation and metric averages of classification with complex-valued artificial neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4def7bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Fold 1 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 4  6]]\n",
      "Accuracy: 0.8000, Precision: 0.8571, Recall: 0.8000, F1 Score: 0.7917\n",
      "\n",
      "Fold 2 Confusion Matrix:\n",
      "[[9 1]\n",
      " [3 7]]\n",
      "Accuracy: 0.8000, Precision: 0.8125, Recall: 0.8000, F1 Score: 0.7980\n",
      "\n",
      "Fold 3 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 4 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 5 Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "Accuracy: 0.8500, Precision: 0.8535, Recall: 0.8500, F1 Score: 0.8496\n",
      "\n",
      "Fold 6 Confusion Matrix:\n",
      "[[7 3]\n",
      " [1 9]]\n",
      "Accuracy: 0.8000, Precision: 0.8125, Recall: 0.8000, F1 Score: 0.7980\n",
      "\n",
      "Fold 7 Confusion Matrix:\n",
      "[[9 1]\n",
      " [3 7]]\n",
      "Accuracy: 0.8000, Precision: 0.8125, Recall: 0.8000, F1 Score: 0.7980\n",
      "\n",
      "Fold 8 Confusion Matrix:\n",
      "[[7 3]\n",
      " [3 7]]\n",
      "Accuracy: 0.7000, Precision: 0.7000, Recall: 0.7000, F1 Score: 0.7000\n",
      "\n",
      "Fold 9 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 10 Confusion Matrix:\n",
      "[[8 2]\n",
      " [2 8]]\n",
      "Accuracy: 0.8000, Precision: 0.8000, Recall: 0.8000, F1 Score: 0.8000\n",
      "\n",
      "Average Accuracy: 0.8400 ± 0.0800\n",
      "Average Precision: 0.8512 ± 0.0788\n",
      "Average Recall: 0.8400 ± 0.0800\n",
      "Average F1 Score: 0.8385 ± 0.0807\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "class ComplexDense(Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super(ComplexDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units, 2),\n",
    "                                      initializer='random_normal',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(shape=(self.units, 2),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs_real, inputs_imag = tf.math.real(inputs), tf.math.imag(inputs)\n",
    "        kernel_real, kernel_imag = self.kernel[..., 0], self.kernel[..., 1]\n",
    "        bias_real, bias_imag = self.bias[..., 0], self.bias[..., 1]\n",
    "\n",
    "        output_real = tf.matmul(inputs_real, kernel_real) - tf.matmul(inputs_imag, kernel_imag) + bias_real\n",
    "        output_imag = tf.matmul(inputs_real, kernel_imag) + tf.matmul(inputs_imag, kernel_real) + bias_imag\n",
    "\n",
    "        output = tf.complex(output_real, output_imag)\n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "def complex_tanh(z):\n",
    "    return tf.complex(tf.math.tanh(tf.math.real(z)), tf.math.tanh(tf.math.imag(z)))\n",
    "\n",
    "def wirtinger_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.complex64)\n",
    "    y_pred = tf.cast(y_pred, tf.complex64)\n",
    "    dF_dz = tf.math.conj(y_pred - y_true) \n",
    "    dF_dz_star = (y_pred - y_true)\n",
    "    return tf.math.abs(dF_dz)**2 + tf.math.abs(dF_dz_star)**2\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel(\"D:\\datasetTEZ\\KİNASE_GPCR_Codon_Complex_Encoding.xlsx\")\n",
    "X = np.array([np.array(list(map(float, x_real.strip(\"[]\").split(',')))) + 1j * np.array(list(map(float, x_imag.strip(\"[]\").split(',')))) for x_real, x_imag in zip(data['Real'], data['Imag'])])\n",
    "y = data['label'].values\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies, precisions, recalls, f1_scores, conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Start cross-validation\n",
    "for train_index, test_index in kf.split(X, np.argmax(y, axis=1)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Model definition\n",
    "    input_layer = Input(shape=(X_train.shape[1],), dtype=tf.complex64)\n",
    "    complex_dense1 = ComplexDense(12, activation=complex_tanh)(input_layer)\n",
    "    complex_dense2 = ComplexDense(8, activation=complex_tanh)(complex_dense1)\n",
    "    complex_dense3 = ComplexDense(6, activation=complex_tanh)(complex_dense2)\n",
    "    output_layer = ComplexDense(2, activation=complex_tanh)(complex_dense3)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.005), loss=wirtinger_loss, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=80, verbose=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision = precision_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "\n",
    "    # Store the results\n",
    "    conf_matrices.append(cm)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Display the results from all folds\n",
    "for i, cm in enumerate(conf_matrices, 1):\n",
    "    print(f\"Fold {i} Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {accuracies[i-1]:.4f}, Precision: {precisions[i-1]:.4f}, Recall: {recalls[i-1]:.4f}, F1 Score: {f1_scores[i-1]:.4f}\\n\")\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the metrics\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "std_precision = np.std(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "std_recall = np.std(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(f\"Average Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45efa415",
   "metadata": {},
   "source": [
    "\n",
    "- b) Real-ANN: Cross-validation and metric averages of classification with real-valued artificial neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cebad838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Fold 1 Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "Accuracy: 0.8500, Precision: 0.8535, Recall: 0.8500, F1 Score: 0.8496\n",
      "\n",
      "Fold 2 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 2  8]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 3 Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "Accuracy: 0.8500, Precision: 0.8535, Recall: 0.8500, F1 Score: 0.8496\n",
      "\n",
      "Fold 4 Confusion Matrix:\n",
      "[[ 9  1]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 5 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 2  8]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 6 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 2  8]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 7 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 8 Confusion Matrix:\n",
      "[[ 9  1]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 9 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 5  5]]\n",
      "Accuracy: 0.7500, Precision: 0.8333, Recall: 0.7500, F1 Score: 0.7333\n",
      "\n",
      "Fold 10 Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "Accuracy: 0.8500, Precision: 0.8535, Recall: 0.8500, F1 Score: 0.8496\n",
      "\n",
      "Average Accuracy: 0.8850 ± 0.0594\n",
      "Average Precision: 0.9008 ± 0.0455\n",
      "Average Recall: 0.8850 ± 0.0594\n",
      "Average F1 Score: 0.8829 ± 0.0632\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"D:\\\\datasetTEZ\\\\KİNASE_GPCR_Kodon_ReelEncoded.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "data['Encoded'] = data['Encoded'].apply(ast.literal_eval)\n",
    "\n",
    "# Separate attributes and tags\n",
    "X = np.array(data['Encoded'].tolist())\n",
    "y = data['label'].values\n",
    "y = to_categorical(y, num_classes=2)  # Convert labels to one-hot encoded format if needed\n",
    "\n",
    "# Standardize data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies, precisions, recalls, f1_scores, conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Start cross-validation\n",
    "for train_index, test_index in kf.split(X, np.argmax(y, axis=1)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=12, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=8, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=6, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=2, activation='sigmoid'))  # Adjust for binary classification\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, batch_size=10, epochs=80, verbose=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision = precision_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "\n",
    "    # Store the results\n",
    "    conf_matrices.append(cm)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Display the results from all folds\n",
    "for i, cm in enumerate(conf_matrices, 1):\n",
    "    print(f\"Fold {i} Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {accuracies[i-1]:.4f}, Precision: {precisions[i-1]:.4f}, Recall: {recalls[i-1]:.4f}, F1 Score: {f1_scores[i-1]:.4f}\\n\")\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the metrics\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "std_precision = np.std(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "std_recall = np.std(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(f\"Average Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7a668",
   "metadata": {},
   "source": [
    "- c) Paired t-test Analysis:\n",
    "\n",
    "In cross-validation, the accuracy results obtained by both methods in each fold can be directly compared using the paired t-test. According to the paired t test results, the t statistic was calculated as -1.1319 and the p value was 0.2869. These results show that the performance difference between the two methods is not statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "87956280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -1.13189888200586, P-value: 0.28693291899495443\n",
      "There is no statistically significant difference between the two models.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Accuracy results of Real and Complex method:\n",
    "complex_method1 = [0.8000, 0.8000, 0.9500, 0.9500, 0.8500, 0.8000, 0.8000, 0.7000, 0.9500, 0.8000]\n",
    "real_method2 = [0.8500, 0.9000, 0.8500, 0.9500, 0.9000, 0.9000, 0.9500, 0.9500, 0.7500, 0.8500]\n",
    "\n",
    "# Paired t-test\n",
    "t_stat, p_value = ttest_rel(complex_method1, real_method2)\n",
    "\n",
    "print(f\"T-Statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the two models.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the two models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa6e02",
   "metadata": {},
   "source": [
    "# 3.\tAmino Acid Sequence Classification: Complex-ANN vs. Real-ANN\n",
    "- a) Complex-ANN: Cross-validation and metric averages of classification with complex-valued artificial neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea914524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Fold 1 Confusion Matrix:\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9000, F1 Score: 0.9000\n",
      "\n",
      "Fold 2 Confusion Matrix:\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9000, F1 Score: 0.9000\n",
      "\n",
      "Fold 3 Confusion Matrix:\n",
      "[[ 6  4]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.8000, Precision: 0.8571, Recall: 0.8000, F1 Score: 0.7917\n",
      "\n",
      "Fold 4 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 5 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 2  8]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 6 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 5  5]]\n",
      "Accuracy: 0.7500, Precision: 0.8333, Recall: 0.7500, F1 Score: 0.7333\n",
      "\n",
      "Fold 7 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 0 10]]\n",
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "\n",
      "Fold 8 Confusion Matrix:\n",
      "[[7 3]\n",
      " [1 9]]\n",
      "Accuracy: 0.8000, Precision: 0.8125, Recall: 0.8000, F1 Score: 0.7980\n",
      "\n",
      "Fold 9 Confusion Matrix:\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9000, F1 Score: 0.9000\n",
      "\n",
      "Fold 10 Confusion Matrix:\n",
      "[[8 2]\n",
      " [3 7]]\n",
      "Accuracy: 0.7500, Precision: 0.7525, Recall: 0.7500, F1 Score: 0.7494\n",
      "\n",
      "Average Accuracy: 0.8650 ± 0.0808\n",
      "Average Precision: 0.8827 ± 0.0678\n",
      "Average Recall: 0.8650 ± 0.0808\n",
      "Average F1 Score: 0.8621 ± 0.0841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "class ComplexDense(Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super(ComplexDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units, 2),\n",
    "                                      initializer='random_normal',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(shape=(self.units, 2),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs_real, inputs_imag = tf.math.real(inputs), tf.math.imag(inputs)\n",
    "        kernel_real, kernel_imag = self.kernel[..., 0], self.kernel[..., 1]\n",
    "        bias_real, bias_imag = self.bias[..., 0], self.bias[..., 1]\n",
    "\n",
    "        output_real = tf.matmul(inputs_real, kernel_real) - tf.matmul(inputs_imag, kernel_imag) + bias_real\n",
    "        output_imag = tf.matmul(inputs_real, kernel_imag) + tf.matmul(inputs_imag, kernel_real) + bias_imag\n",
    "\n",
    "        output = tf.complex(output_real, output_imag)\n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "    \n",
    "def complex_tanh(z):\n",
    "    return tf.complex(tf.math.tanh(tf.math.real(z)), tf.math.tanh(tf.math.imag(z)))\n",
    "\n",
    "def wirtinger_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.complex64)\n",
    "    y_pred = tf.cast(y_pred, tf.complex64)\n",
    "    dF_dz = tf.math.conj(y_pred - y_true) \n",
    "    dF_dz_star = (y_pred - y_true)\n",
    "    return tf.math.abs(dF_dz)**2 + tf.math.abs(dF_dz_star)**2\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel(\"D:\\datasetTEZ\\Kinase_GPCR_AminoAcid_Fasta_Complex_Encoded.xlsx\")\n",
    "X = np.array([np.array(list(map(float, x_real.strip(\"[]\").split(',')))) + 1j * np.array(list(map(float, x_imag.strip(\"[]\").split(',')))) for x_real, x_imag in zip(data['Real'], data['Imag'])])\n",
    "y = data['label'].values\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies, precisions, recalls, f1_scores, conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Start cross-validation\n",
    "for train_index, test_index in kf.split(X, np.argmax(y, axis=1)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Model definition\n",
    "    input_layer = Input(shape=(X_train.shape[1],), dtype=tf.complex64)\n",
    "    complex_dense1 = ComplexDense(12, activation=complex_tanh)(input_layer)\n",
    "    complex_dense2 = ComplexDense(8, activation=complex_tanh)(complex_dense1)\n",
    "    complex_dense3 = ComplexDense(6, activation=complex_tanh)(complex_dense2)\n",
    "    output_layer = ComplexDense(2, activation=complex_tanh)(complex_dense3)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.005), loss=wirtinger_loss, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, batch_size=10, epochs=80, verbose=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision = precision_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "\n",
    "    # Store the results\n",
    "    conf_matrices.append(cm)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Display the results from all folds\n",
    "for i, cm in enumerate(conf_matrices, 1):\n",
    "    print(f\"Fold {i} Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {accuracies[i-1]:.4f}, Precision: {precisions[i-1]:.4f}, Recall: {recalls[i-1]:.4f}, F1 Score: {f1_scores[i-1]:.4f}\\n\")\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the metrics\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "std_precision = np.std(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "std_recall = np.std(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(f\"Average Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5830faf0",
   "metadata": {},
   "source": [
    "\n",
    "- b) Real-ANN: Cross-validation and metric averages of classification with real-valued artificial neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9f9804dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Fold 1 Confusion Matrix:\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9000, F1 Score: 0.9000\n",
      "\n",
      "Fold 2 Confusion Matrix:\n",
      "[[ 7  3]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.8500, Precision: 0.8846, Recall: 0.8500, F1 Score: 0.8465\n",
      "\n",
      "Fold 3 Confusion Matrix:\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "Accuracy: 0.9000, Precision: 0.9000, Recall: 0.9000, F1 Score: 0.9000\n",
      "\n",
      "Fold 4 Confusion Matrix:\n",
      "[[ 5  5]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.7500, Precision: 0.8333, Recall: 0.7500, F1 Score: 0.7333\n",
      "\n",
      "Fold 5 Confusion Matrix:\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "Accuracy: 0.9000, Precision: 0.9167, Recall: 0.9000, F1 Score: 0.8990\n",
      "\n",
      "Fold 6 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 7 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 1  9]]\n",
      "Accuracy: 0.9500, Precision: 0.9545, Recall: 0.9500, F1 Score: 0.9499\n",
      "\n",
      "Fold 8 Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "Accuracy: 0.8500, Precision: 0.8535, Recall: 0.8500, F1 Score: 0.8496\n",
      "\n",
      "Fold 9 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 4  6]]\n",
      "Accuracy: 0.8000, Precision: 0.8571, Recall: 0.8000, F1 Score: 0.7917\n",
      "\n",
      "Fold 10 Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 0 10]]\n",
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "\n",
      "Average Accuracy: 0.8850 ± 0.0709\n",
      "Average Precision: 0.9054 ± 0.0496\n",
      "Average Recall: 0.8850 ± 0.0709\n",
      "Average F1 Score: 0.8820 ± 0.0753\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"D:\\datasetTEZ\\KİNASE_GPCR_AminoAcid_EncodedReel.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "data['Encoded'] = data['Encoded'].apply(ast.literal_eval)\n",
    "\n",
    "# Separate attributes and tags\n",
    "X = np.array(data['Encoded'].tolist())\n",
    "y = data['label'].values\n",
    "y = to_categorical(y, num_classes=2)  # Convert labels to one-hot encoded format if needed\n",
    "\n",
    "# Standardize data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies, precisions, recalls, f1_scores, conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Start cross-validation\n",
    "for train_index, test_index in kf.split(X, np.argmax(y, axis=1)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=12, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=8, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=6, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=2, activation='sigmoid'))  # Adjust for binary classification\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, batch_size=10, epochs=80, verbose=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision = precision_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "\n",
    "    # Store the results\n",
    "    conf_matrices.append(cm)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Display the results from all folds\n",
    "for i, cm in enumerate(conf_matrices, 1):\n",
    "    print(f\"Fold {i} Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {accuracies[i-1]:.4f}, Precision: {precisions[i-1]:.4f}, Recall: {recalls[i-1]:.4f}, F1 Score: {f1_scores[i-1]:.4f}\\n\")\n",
    "\n",
    "# Calculate and display the mean and standard deviation of the metrics\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "std_precision = np.std(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "std_recall = np.std(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(f\"Average Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f09caae",
   "metadata": {},
   "source": [
    "- c) Paired t-test Analysis:\n",
    "\n",
    "In cross-validation, the accuracy results obtained by both methods in each fold can be directly compared using the paired t-test. According to the paired t test results, the t statistic was calculated as -0.4657 and the p value was 0.6525. These results show that the performance difference between the two methods is not statistically significant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a71467f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -0.46569031542379935, P-value: 0.652501015204662\n",
      "There is no statistically significant difference between the two models.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Accuracy results of Real and Complex method:\n",
    "complex_method1 = [0.9000, 0.9000, 0.8000, 0.9500, 0.9000, 0.7500, 1.0000, 0.8000, 0.9000, 0.7500]\n",
    "real_method2 = [0.9000, 0.8500, 0.9000, 0.7500, 0.9000, 0.9500, 0.9500, 0.8500, 0.8000, 1.0000]\n",
    "\n",
    "# Paired t-test\n",
    "t_stat, p_value = ttest_rel(complex_method1, real_method2)\n",
    "\n",
    "print(f\"T-Statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the two models.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the two models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9d316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
